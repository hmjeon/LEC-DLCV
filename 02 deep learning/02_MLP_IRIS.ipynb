{"cells":[{"cell_type":"markdown","metadata":{"id":"XuGhasH-hXtw"},"source":["### **Multilayer Perceptron - PyTorch**"]},{"cell_type":"markdown","source":["\n","#### [Step 1] Dataset & DataLoader\n","\n","- **Dataset** : Dataset 클래스를 상속 --> Custom Instance를 생성\n","\n","- **DataLoader**: 학습 시 각 Instance에 쉽게 접근하기 위해 순회 가능한 객체(iterable) 생성, shuffling 및 batch 등의 작업 수행\n","\n","<p align=\"center\">\n","<img src = https://sebastianraschka.com/images/blog/2022/datapipes/loader-flow.png width = 500>\n","</p>\n","\n","<p align=\"center\">\n","<img src = https://sebastianraschka.com/images/blog/2022/datapipes/dataflow-good.png width = 350>\n","</p>\n","\n","- **Sample code**\n","```\n","from torch.utils.data import  TensorDataset, DataLoader\n","```\n","```\n","# X,y로 분할한 데이터를 tensor로 변환\n","X_train = torch.tensor(X_train, dtype=torch.float32)\n","X_test = torch.tensor(X_test, dtype=torch.float32)\n","y_train = torch.tensor(y_train, dtype=torch.int64)\n","y_test = torch.tensor(y_test, dtype=torch.int64)\n","```\n","```\n","# tensor를 TensorDataset으로 생성 - X와 y가 짝으로 이루어짐\n","train_dataset = TensorDataset(X_train, y_train)\n","test_dataset = TensorDataset(X_test, y_test)\n","```\n","```\n","# DataLoader 형태로 생성\n","train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=True)\n","```"],"metadata":{"id":"agoI8uI4u2Tg"}},{"cell_type":"markdown","source":["\n","#### [Step 2] 디바이스 설정\n","\n","- 일반적으로 인공신경망의 학습은 (가능하다면) GPU를 사용하는 것이 바람직함\n","    - Colab Runtime 설정 변경\n","- GPU를 사용하여 학습을 진행하도록 명시적으로 작성 필요\n","- 연산 유형에 따라 GPU에서 수행이 불가능한 경우도 존재하는데, 그럴 경우도 마찬가지로 명시적으로 어떤 프로세서에서 연산을 수행해야하는지 코드로 작성해야함 \n","\n","```\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model = NeuralNetwork().to(device)\n","```\n"],"metadata":{"id":"r9aKhw3gzx8c"}},{"cell_type":"markdown","source":["#### [Step 3] 신경망 모델 생성\n","\n","- **torch.nn 패키지**는 신경망 생성 및 학습 시 설정해야하는 다양한 기능을 제공\n","\n","```\n","import torch.nn as nn\n","```\n","- 신경망을 **nn.Module**을 상속받아 정의\n","    - __ __init__ __(): 신경망에서 사용할 layer를 초기화하는 부분\n","    - __forward()__: feed foward 연산 수행 시, 각 layer의 입출력이 어떻게 연결되는지를 지정\n","\n","```\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.input_layer    = nn.Linear(4, 16)\n","        self.hidden_layer1  = nn.Linear(16, 32)\n","        self.output_layer   = nn.Linear(32, 3)\n","        self.relu = nn.ReLU()\n","    \n","    def forward(self, x):\n","        out =  self.relu(self.input_layer(x))\n","        out =  self.relu(self.hidden_layer1(out))\n","        out =  self.output_layer(out)\n","        return out\n","\n","```\n"],"metadata":{"id":"mU4GSmP11aOi"}},{"cell_type":"markdown","source":["#### [Step 4] 네트워크 컴파일(Compiling)\n","\n","- 학습 시 필요한 정보들(loss function, optimizer)을 선언\n","- 일반적으로 loss와 optimizer는 아래와 같이 변수로 선언하고, 변수를 train/test 시 참고할 수 있도록 매개변수로 지정해줌 \n","\n","```\n","learning_rate = 0.01\n","loss = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n","```\n"],"metadata":{"id":"o47oW5LG2KvT"}},{"cell_type":"markdown","source":["#### [Step 5] 네트워크 학습(Training)\n","\n","- **신경망의 학습과정**을 별도의 함수로 구성하는 것이 일반적\n","    - feed forward -> loss -> error back propagation -> (log) -> (반복)\n","\n","```\n","def train_loop(train_loader, model, loss_fn, optimizer):\n","    for batch, (X, y) in enumerate(train_loader):\n","        X, y = X.to(device), y.to(device)\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","```"],"metadata":{"id":"ZU_4khRU28kP"}},{"cell_type":"markdown","source":["#### [Step 6] 학습된 네트워크 테스트\n","\n","- 학습과정과 비슷하나 error back propagate하는 부분이 없음\n","    - feed forward -> loss ->  (log) -> (반복)\n","\n","```\n","def test_loop(test_loader, model, loss_fn):\n","    size = len(test_loader.dataset)\n","    num_batches = len(test_loader)\n","    test_loss, correct = 0, 0\n","\n","    with torch.no_grad():\n","        for X, y in test_loader:\n","            X, y = X.to(device), y.to(device)\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","\n","    test_loss /= num_batches\n","    correct /= size\n","    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:8f}\\n\")\n"],"metadata":{"id":"DI_l_z043pVW"}},{"cell_type":"markdown","source":["#### [Step 7] Iteration\n","- 신경망 학습은 여러 epochs을 반복해서 수행하면서 모델을 구성하는 최적의 파라미터를 찾음\n","- 지정한 epochs 수만큼 **학습**과정과 **평가**과정을 반복하면서, 모델의 성능(loss, accuracy 등)을 체크함\n","\n","```\n","epochs = 10\n","for i in range(epochs) :\n","    print(f\"Epoch {i+1} \\n------------------------\")\n","    train_loop(train_dataloader, model, loss, optimizer)\n","    test_loop(test_dataloader, model, loss)\n","print(\"Done!\")\n","```"],"metadata":{"id":"NepldSZC4SQT"}},{"cell_type":"markdown","source":["### **MLP - IRIS 데이터셋**\n","\n","데이터설명 : 아이리스(붓꽃) 데이터에 대한 데이터이다. 꽃잎의 각 부분의 너비와 길이등을 측정한 데이터이며 150개의 레코드로 구성되어 있다. 아이리스 꽃은 아래의 그림과 같다. 프랑스의 국화라고 한다.\n","\n","- 데이터명 : IRIS (아이리스, 붗꽃 데이터)  \n","- 레코드수 : 150개\n","- 필드개수 : 5개(총 6개의 필드로 구성, caseno는 순서를 표시하므로 분석에서 제외), 2번째부터 5번째의 4개의 필드는 입력 변수로 사용되고, 맨 아래의 Species 속성이 목표(종속) 변수로 사용된다.\n","\n","  - caseno\t일련번호이다. (1부터 150까지 입력된다.)\n","  - Sepal Length\t꽃받침의 길이 정보이다.\n","  - Sepal Width\t꽃받침의 너비 정보이다.\n","  - Petal Length\t꽃잎의 길이 정보이다.\n","  - Petal Width\t꽃잎의 너비 정보이다.  \n","  - Species\t꽃의 종류 정보이다.  setosa / versicolor / virginica 의 3종류로 구분된다."],"metadata":{"id":"RdWSITNN5N55"}},{"cell_type":"markdown","source":["#### [Step 01] Load libraries & Datasets\n","\n"],"metadata":{"id":"_OZS5t3_5fq8"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"cyZUXXJkhXt1","executionInfo":{"status":"ok","timestamp":1675613864281,"user_tz":-540,"elapsed":3,"user":{"displayName":"Hyungmin Jun","userId":"09878601996915185956"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import  TensorDataset, DataLoader\n","\n","# 데이터 불러오기\n","iris = load_iris()\n","df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n","\n"]},{"cell_type":"code","source":["print(df.shape)\n","df.describe()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"id":"d-Z4vCe0Xke3","executionInfo":{"status":"ok","timestamp":1675614001855,"user_tz":-540,"elapsed":858,"user":{"displayName":"Hyungmin Jun","userId":"09878601996915185956"}},"outputId":"6e89f297-5a1a-4fdf-8631-685e33dffcf4"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["(150, 4)\n"]},{"output_type":"execute_result","data":{"text/plain":["       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n","count         150.000000        150.000000         150.000000   \n","mean            5.843333          3.057333           3.758000   \n","std             0.828066          0.435866           1.765298   \n","min             4.300000          2.000000           1.000000   \n","25%             5.100000          2.800000           1.600000   \n","50%             5.800000          3.000000           4.350000   \n","75%             6.400000          3.300000           5.100000   \n","max             7.900000          4.400000           6.900000   \n","\n","       petal width (cm)  \n","count        150.000000  \n","mean           1.199333  \n","std            0.762238  \n","min            0.100000  \n","25%            0.300000  \n","50%            1.300000  \n","75%            1.800000  \n","max            2.500000  "],"text/html":["\n","  <div id=\"df-f352591b-215e-40f8-95a2-20aebe0f415a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepal length (cm)</th>\n","      <th>sepal width (cm)</th>\n","      <th>petal length (cm)</th>\n","      <th>petal width (cm)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>150.000000</td>\n","      <td>150.000000</td>\n","      <td>150.000000</td>\n","      <td>150.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>5.843333</td>\n","      <td>3.057333</td>\n","      <td>3.758000</td>\n","      <td>1.199333</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.828066</td>\n","      <td>0.435866</td>\n","      <td>1.765298</td>\n","      <td>0.762238</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>4.300000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>0.100000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>5.100000</td>\n","      <td>2.800000</td>\n","      <td>1.600000</td>\n","      <td>0.300000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>5.800000</td>\n","      <td>3.000000</td>\n","      <td>4.350000</td>\n","      <td>1.300000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>6.400000</td>\n","      <td>3.300000</td>\n","      <td>5.100000</td>\n","      <td>1.800000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>7.900000</td>\n","      <td>4.400000</td>\n","      <td>6.900000</td>\n","      <td>2.500000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f352591b-215e-40f8-95a2-20aebe0f415a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f352591b-215e-40f8-95a2-20aebe0f415a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f352591b-215e-40f8-95a2-20aebe0f415a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":[],"metadata":{"id":"Hti304nUYCEP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['label'] = iris.target\n","\n","# 데이터분할\n","y = df['label']\n","X = df.drop(['label'], axis=1)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, random_state=42, stratify=y)"],"metadata":{"id":"3TGEe3NMWktD","executionInfo":{"status":"ok","timestamp":1675614047731,"user_tz":-540,"elapsed":461,"user":{"displayName":"Hyungmin Jun","userId":"09878601996915185956"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["#### [Step2] Create DataLoader"],"metadata":{"id":"zK8W6dJw5t2j"}},{"cell_type":"code","source":["X_train = torch.tensor(X_train, dtype=torch.float32)\n","X_test = torch.tensor(X_test, dtype=torch.float32)\n","y_train = torch.tensor(y_train, dtype=torch.int64)\n","y_test = torch.tensor(y_test, dtype=torch.int64)\n","\n","train_dataset = TensorDataset(X_train, y_train)\n","test_dataset = TensorDataset(X_test, y_test)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=True)"],"metadata":{"id":"vhABi-mw5sZa","executionInfo":{"status":"ok","timestamp":1675614052198,"user_tz":-540,"elapsed":609,"user":{"displayName":"Hyungmin Jun","userId":"09878601996915185956"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["#### [Step3] Set Network Structure"],"metadata":{"id":"_0wC3m4k55xF"}},{"cell_type":"code","source":["class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.input_layer    = nn.Linear(4, 16)\n","        self.hidden_layer1  = nn.Linear(16, 32)\n","        self.output_layer   = nn.Linear(32, 3)\n","        self.relu = nn.ReLU()    \n","    \n","    def forward(self,x):\n","        out =  self.relu(self.input_layer(x))\n","        out =  self.relu(self.hidden_layer1(out))\n","        out =  self.output_layer(out)\n","        return out"],"metadata":{"id":"E2GUrsiR5yiZ","executionInfo":{"status":"ok","timestamp":1675614058392,"user_tz":-540,"elapsed":446,"user":{"displayName":"Hyungmin Jun","userId":"09878601996915185956"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["#### [Step4] Create Model instance"],"metadata":{"id":"-vdPdjRF6AqV"}},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(f'device = {device}')\n","\n","model = NeuralNetwork().to(device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w8GAkAm153uV","outputId":"2617c205-eeb0-473b-e0bc-51545f6741d8","executionInfo":{"status":"ok","timestamp":1675614067415,"user_tz":-540,"elapsed":4529,"user":{"displayName":"Hyungmin Jun","userId":"09878601996915185956"}}},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["device = cuda\n"]}]},{"cell_type":"markdown","source":["#### [Step5] Model compile"],"metadata":{"id":"TtK-wiwb6Nkh"}},{"cell_type":"code","source":["# 모델 컴파일\n","learning_rate = 0.001\n","loss = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"],"metadata":{"id":"5tsuBMep6MK2","executionInfo":{"status":"ok","timestamp":1675614071719,"user_tz":-540,"elapsed":1080,"user":{"displayName":"Hyungmin Jun","userId":"09878601996915185956"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["#### [Step6] Set train loop"],"metadata":{"id":"FIv0Csq76YGU"}},{"cell_type":"code","source":["def train_loop(train_loader, model, loss_fn, optimizer):\n","    size = len(train_loader.dataset)\n","\n","    for batch, (X, y) in enumerate(train_loader):\n","        X, y = X.to(device), y.to(device)\n","        pred = model(X)\n","\n","        # 손실 계산\n","        loss = loss_fn(pred, y)\n","\n","        # 역전파\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        loss, current = loss.item(), batch * len(X)\n","        print(f'loss: {loss:>7f}  [{current:>5d}]/{size:5d}')\n"],"metadata":{"id":"yBIp4bGA6TE-","executionInfo":{"status":"ok","timestamp":1675614078075,"user_tz":-540,"elapsed":451,"user":{"displayName":"Hyungmin Jun","userId":"09878601996915185956"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["#### [Step7] Set test loop"],"metadata":{"id":"uFQY-H_i6hz7"}},{"cell_type":"code","source":["def test_loop(test_loader, model, loss_fn):\n","    size = len(test_loader.dataset)\n","    num_batches = len(test_loader)\n","    test_loss, correct = 0, 0\n","\n","    with torch.no_grad():\n","        for X, y in test_loader:\n","            X, y = X.to(device), y.to(device)\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","\n","    test_loss /= num_batches\n","    correct /= size\n","    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:8f}\\n\")"],"metadata":{"id":"pi2tohiS6gbe","executionInfo":{"status":"ok","timestamp":1675614082950,"user_tz":-540,"elapsed":473,"user":{"displayName":"Hyungmin Jun","userId":"09878601996915185956"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["#### [Step8] Run model"],"metadata":{"id":"WeM2SWZg6mr1"}},{"cell_type":"code","source":["# 모델 실행\n","epochs = 100\n","\n","for i in range(epochs) :\n","    print(f\"Epoch {i+1} \\n------------------------\")\n","    train_loop(train_dataloader, model, loss, optimizer)\n","    test_loop(test_dataloader, model, loss)\n","print(\"Done!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n5BwYOdq6lzl","outputId":"eb1abb24-c76c-4a91-8f0a-2964996666fe","executionInfo":{"status":"ok","timestamp":1675614134452,"user_tz":-540,"elapsed":3002,"user":{"displayName":"Hyungmin Jun","userId":"09878601996915185956"}}},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 \n","------------------------\n","loss: 0.452185  [    0]/  112\n","loss: 0.612783  [   10]/  112\n","loss: 0.301838  [   20]/  112\n","loss: 0.385962  [   30]/  112\n","loss: 0.694239  [   40]/  112\n","loss: 0.585045  [   50]/  112\n","loss: 0.595845  [   60]/  112\n","loss: 0.393974  [   70]/  112\n","loss: 0.408531  [   80]/  112\n","loss: 0.483114  [   90]/  112\n","loss: 0.474614  [  100]/  112\n","loss: 0.501538  [   22]/  112\n","Test Error: \n"," Accuracy: 76.3%, Avg loss: 0.495204\n","\n","Epoch 2 \n","------------------------\n","loss: 0.507666  [    0]/  112\n","loss: 0.529120  [   10]/  112\n","loss: 0.520601  [   20]/  112\n","loss: 0.389667  [   30]/  112\n","loss: 0.238824  [   40]/  112\n","loss: 0.366642  [   50]/  112\n","loss: 0.590740  [   60]/  112\n","loss: 0.580313  [   70]/  112\n","loss: 0.527533  [   80]/  112\n","loss: 0.377504  [   90]/  112\n","loss: 0.539492  [  100]/  112\n","loss: 0.492341  [   22]/  112\n","Test Error: \n"," Accuracy: 81.6%, Avg loss: 0.482780\n","\n","Epoch 3 \n","------------------------\n","loss: 0.569176  [    0]/  112\n","loss: 0.341312  [   10]/  112\n","loss: 0.350611  [   20]/  112\n","loss: 0.520468  [   30]/  112\n","loss: 0.402760  [   40]/  112\n","loss: 0.397239  [   50]/  112\n","loss: 0.512702  [   60]/  112\n","loss: 0.321122  [   70]/  112\n","loss: 0.535807  [   80]/  112\n","loss: 0.453775  [   90]/  112\n","loss: 0.544600  [  100]/  112\n","loss: 0.332770  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.449334\n","\n","Epoch 4 \n","------------------------\n","loss: 0.506219  [    0]/  112\n","loss: 0.473521  [   10]/  112\n","loss: 0.282765  [   20]/  112\n","loss: 0.372321  [   30]/  112\n","loss: 0.620928  [   40]/  112\n","loss: 0.436643  [   50]/  112\n","loss: 0.515274  [   60]/  112\n","loss: 0.367687  [   70]/  112\n","loss: 0.348488  [   80]/  112\n","loss: 0.275269  [   90]/  112\n","loss: 0.447412  [  100]/  112\n","loss: 0.551800  [   22]/  112\n","Test Error: \n"," Accuracy: 92.1%, Avg loss: 0.440167\n","\n","Epoch 5 \n","------------------------\n","loss: 0.404092  [    0]/  112\n","loss: 0.356346  [   10]/  112\n","loss: 0.564224  [   20]/  112\n","loss: 0.576989  [   30]/  112\n","loss: 0.354150  [   40]/  112\n","loss: 0.468529  [   50]/  112\n","loss: 0.362686  [   60]/  112\n","loss: 0.252224  [   70]/  112\n","loss: 0.570754  [   80]/  112\n","loss: 0.344629  [   90]/  112\n","loss: 0.305160  [  100]/  112\n","loss: 0.033574  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.409366\n","\n","Epoch 6 \n","------------------------\n","loss: 0.489629  [    0]/  112\n","loss: 0.397504  [   10]/  112\n","loss: 0.431314  [   20]/  112\n","loss: 0.240049  [   30]/  112\n","loss: 0.460988  [   40]/  112\n","loss: 0.418275  [   50]/  112\n","loss: 0.391874  [   60]/  112\n","loss: 0.413800  [   70]/  112\n","loss: 0.424499  [   80]/  112\n","loss: 0.292394  [   90]/  112\n","loss: 0.390322  [  100]/  112\n","loss: 0.025849  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.389267\n","\n","Epoch 7 \n","------------------------\n","loss: 0.529306  [    0]/  112\n","loss: 0.234920  [   10]/  112\n","loss: 0.443566  [   20]/  112\n","loss: 0.419431  [   30]/  112\n","loss: 0.268845  [   40]/  112\n","loss: 0.513116  [   50]/  112\n","loss: 0.459292  [   60]/  112\n","loss: 0.299781  [   70]/  112\n","loss: 0.352603  [   80]/  112\n","loss: 0.290021  [   90]/  112\n","loss: 0.315542  [  100]/  112\n","loss: 0.219254  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.380005\n","\n","Epoch 8 \n","------------------------\n","loss: 0.362216  [    0]/  112\n","loss: 0.304061  [   10]/  112\n","loss: 0.351690  [   20]/  112\n","loss: 0.320252  [   30]/  112\n","loss: 0.405773  [   40]/  112\n","loss: 0.334242  [   50]/  112\n","loss: 0.398646  [   60]/  112\n","loss: 0.411870  [   70]/  112\n","loss: 0.463426  [   80]/  112\n","loss: 0.304438  [   90]/  112\n","loss: 0.295546  [  100]/  112\n","loss: 0.257909  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.360883\n","\n","Epoch 9 \n","------------------------\n","loss: 0.310093  [    0]/  112\n","loss: 0.368099  [   10]/  112\n","loss: 0.339979  [   20]/  112\n","loss: 0.351399  [   30]/  112\n","loss: 0.451509  [   40]/  112\n","loss: 0.398139  [   50]/  112\n","loss: 0.334159  [   60]/  112\n","loss: 0.278404  [   70]/  112\n","loss: 0.247943  [   80]/  112\n","loss: 0.257643  [   90]/  112\n","loss: 0.388697  [  100]/  112\n","loss: 0.516262  [   22]/  112\n","Test Error: \n"," Accuracy: 92.1%, Avg loss: 0.342382\n","\n","Epoch 10 \n","------------------------\n","loss: 0.300470  [    0]/  112\n","loss: 0.256571  [   10]/  112\n","loss: 0.248664  [   20]/  112\n","loss: 0.251919  [   30]/  112\n","loss: 0.433236  [   40]/  112\n","loss: 0.337672  [   50]/  112\n","loss: 0.401237  [   60]/  112\n","loss: 0.389149  [   70]/  112\n","loss: 0.265515  [   80]/  112\n","loss: 0.298154  [   90]/  112\n","loss: 0.429578  [  100]/  112\n","loss: 0.262548  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.325613\n","\n","Epoch 11 \n","------------------------\n","loss: 0.256063  [    0]/  112\n","loss: 0.436430  [   10]/  112\n","loss: 0.244625  [   20]/  112\n","loss: 0.442360  [   30]/  112\n","loss: 0.378314  [   40]/  112\n","loss: 0.218582  [   50]/  112\n","loss: 0.175278  [   60]/  112\n","loss: 0.327493  [   70]/  112\n","loss: 0.296526  [   80]/  112\n","loss: 0.250744  [   90]/  112\n","loss: 0.457468  [  100]/  112\n","loss: 0.020399  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.312847\n","\n","Epoch 12 \n","------------------------\n","loss: 0.335574  [    0]/  112\n","loss: 0.271400  [   10]/  112\n","loss: 0.354928  [   20]/  112\n","loss: 0.146836  [   30]/  112\n","loss: 0.253958  [   40]/  112\n","loss: 0.316488  [   50]/  112\n","loss: 0.393595  [   60]/  112\n","loss: 0.339199  [   70]/  112\n","loss: 0.319713  [   80]/  112\n","loss: 0.387503  [   90]/  112\n","loss: 0.264530  [  100]/  112\n","loss: 0.207732  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.302026\n","\n","Epoch 13 \n","------------------------\n","loss: 0.323193  [    0]/  112\n","loss: 0.227478  [   10]/  112\n","loss: 0.407415  [   20]/  112\n","loss: 0.229904  [   30]/  112\n","loss: 0.345547  [   40]/  112\n","loss: 0.204888  [   50]/  112\n","loss: 0.434696  [   60]/  112\n","loss: 0.272531  [   70]/  112\n","loss: 0.201344  [   80]/  112\n","loss: 0.260680  [   90]/  112\n","loss: 0.247444  [  100]/  112\n","loss: 0.228886  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.279755\n","\n","Epoch 14 \n","------------------------\n","loss: 0.199114  [    0]/  112\n","loss: 0.303666  [   10]/  112\n","loss: 0.310792  [   20]/  112\n","loss: 0.265330  [   30]/  112\n","loss: 0.229402  [   40]/  112\n","loss: 0.298758  [   50]/  112\n","loss: 0.277266  [   60]/  112\n","loss: 0.342840  [   70]/  112\n","loss: 0.259098  [   80]/  112\n","loss: 0.274704  [   90]/  112\n","loss: 0.310384  [  100]/  112\n","loss: 0.020791  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.273794\n","\n","Epoch 15 \n","------------------------\n","loss: 0.131279  [    0]/  112\n","loss: 0.237672  [   10]/  112\n","loss: 0.338212  [   20]/  112\n","loss: 0.264981  [   30]/  112\n","loss: 0.264795  [   40]/  112\n","loss: 0.250851  [   50]/  112\n","loss: 0.238216  [   60]/  112\n","loss: 0.259488  [   70]/  112\n","loss: 0.328810  [   80]/  112\n","loss: 0.368620  [   90]/  112\n","loss: 0.226672  [  100]/  112\n","loss: 0.060438  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.264626\n","\n","Epoch 16 \n","------------------------\n","loss: 0.360475  [    0]/  112\n","loss: 0.157526  [   10]/  112\n","loss: 0.185963  [   20]/  112\n","loss: 0.207445  [   30]/  112\n","loss: 0.265953  [   40]/  112\n","loss: 0.515691  [   50]/  112\n","loss: 0.178764  [   60]/  112\n","loss: 0.158585  [   70]/  112\n","loss: 0.189739  [   80]/  112\n","loss: 0.294625  [   90]/  112\n","loss: 0.215047  [  100]/  112\n","loss: 0.333942  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.256292\n","\n","Epoch 17 \n","------------------------\n","loss: 0.112740  [    0]/  112\n","loss: 0.245602  [   10]/  112\n","loss: 0.151893  [   20]/  112\n","loss: 0.462049  [   30]/  112\n","loss: 0.246050  [   40]/  112\n","loss: 0.262658  [   50]/  112\n","loss: 0.356790  [   60]/  112\n","loss: 0.121683  [   70]/  112\n","loss: 0.199910  [   80]/  112\n","loss: 0.288591  [   90]/  112\n","loss: 0.260718  [  100]/  112\n","loss: 0.163254  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.241642\n","\n","Epoch 18 \n","------------------------\n","loss: 0.213735  [    0]/  112\n","loss: 0.217600  [   10]/  112\n","loss: 0.270236  [   20]/  112\n","loss: 0.221383  [   30]/  112\n","loss: 0.276091  [   40]/  112\n","loss: 0.219050  [   50]/  112\n","loss: 0.217830  [   60]/  112\n","loss: 0.298278  [   70]/  112\n","loss: 0.264243  [   80]/  112\n","loss: 0.292598  [   90]/  112\n","loss: 0.096075  [  100]/  112\n","loss: 0.541304  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.231079\n","\n","Epoch 19 \n","------------------------\n","loss: 0.369984  [    0]/  112\n","loss: 0.198885  [   10]/  112\n","loss: 0.137239  [   20]/  112\n","loss: 0.307844  [   30]/  112\n","loss: 0.205617  [   40]/  112\n","loss: 0.200271  [   50]/  112\n","loss: 0.312828  [   60]/  112\n","loss: 0.414819  [   70]/  112\n","loss: 0.255667  [   80]/  112\n","loss: 0.176708  [   90]/  112\n","loss: 0.187838  [  100]/  112\n","loss: 0.048604  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.221852\n","\n","Epoch 20 \n","------------------------\n","loss: 0.107966  [    0]/  112\n","loss: 0.270559  [   10]/  112\n","loss: 0.210004  [   20]/  112\n","loss: 0.203658  [   30]/  112\n","loss: 0.277893  [   40]/  112\n","loss: 0.189581  [   50]/  112\n","loss: 0.212973  [   60]/  112\n","loss: 0.165916  [   70]/  112\n","loss: 0.154114  [   80]/  112\n","loss: 0.269528  [   90]/  112\n","loss: 0.296318  [  100]/  112\n","loss: 0.081059  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.212744\n","\n","Epoch 21 \n","------------------------\n","loss: 0.278547  [    0]/  112\n","loss: 0.131675  [   10]/  112\n","loss: 0.243097  [   20]/  112\n","loss: 0.231145  [   30]/  112\n","loss: 0.162412  [   40]/  112\n","loss: 0.119562  [   50]/  112\n","loss: 0.129501  [   60]/  112\n","loss: 0.211760  [   70]/  112\n","loss: 0.163270  [   80]/  112\n","loss: 0.298719  [   90]/  112\n","loss: 0.248802  [  100]/  112\n","loss: 0.177543  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.211299\n","\n","Epoch 22 \n","------------------------\n","loss: 0.139989  [    0]/  112\n","loss: 0.196811  [   10]/  112\n","loss: 0.239791  [   20]/  112\n","loss: 0.135430  [   30]/  112\n","loss: 0.242426  [   40]/  112\n","loss: 0.198095  [   50]/  112\n","loss: 0.122834  [   60]/  112\n","loss: 0.131852  [   70]/  112\n","loss: 0.269728  [   80]/  112\n","loss: 0.279341  [   90]/  112\n","loss: 0.231563  [  100]/  112\n","loss: 0.154224  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.196528\n","\n","Epoch 23 \n","------------------------\n","loss: 0.214554  [    0]/  112\n","loss: 0.090567  [   10]/  112\n","loss: 0.211097  [   20]/  112\n","loss: 0.107467  [   30]/  112\n","loss: 0.113218  [   40]/  112\n","loss: 0.337568  [   50]/  112\n","loss: 0.344872  [   60]/  112\n","loss: 0.193206  [   70]/  112\n","loss: 0.187249  [   80]/  112\n","loss: 0.150996  [   90]/  112\n","loss: 0.101133  [  100]/  112\n","loss: 0.375229  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.202584\n","\n","Epoch 24 \n","------------------------\n","loss: 0.082244  [    0]/  112\n","loss: 0.223888  [   10]/  112\n","loss: 0.226172  [   20]/  112\n","loss: 0.193190  [   30]/  112\n","loss: 0.213698  [   40]/  112\n","loss: 0.195167  [   50]/  112\n","loss: 0.174504  [   60]/  112\n","loss: 0.250430  [   70]/  112\n","loss: 0.186951  [   80]/  112\n","loss: 0.231493  [   90]/  112\n","loss: 0.100181  [  100]/  112\n","loss: 0.256013  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.182005\n","\n","Epoch 25 \n","------------------------\n","loss: 0.201039  [    0]/  112\n","loss: 0.153808  [   10]/  112\n","loss: 0.081006  [   20]/  112\n","loss: 0.167853  [   30]/  112\n","loss: 0.164297  [   40]/  112\n","loss: 0.212130  [   50]/  112\n","loss: 0.370429  [   60]/  112\n","loss: 0.141821  [   70]/  112\n","loss: 0.218354  [   80]/  112\n","loss: 0.161774  [   90]/  112\n","loss: 0.236197  [  100]/  112\n","loss: 0.086320  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.175448\n","\n","Epoch 26 \n","------------------------\n","loss: 0.092067  [    0]/  112\n","loss: 0.217580  [   10]/  112\n","loss: 0.141742  [   20]/  112\n","loss: 0.345160  [   30]/  112\n","loss: 0.096112  [   40]/  112\n","loss: 0.189237  [   50]/  112\n","loss: 0.190509  [   60]/  112\n","loss: 0.094090  [   70]/  112\n","loss: 0.133187  [   80]/  112\n","loss: 0.266805  [   90]/  112\n","loss: 0.055293  [  100]/  112\n","loss: 0.497004  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.170831\n","\n","Epoch 27 \n","------------------------\n","loss: 0.173384  [    0]/  112\n","loss: 0.237057  [   10]/  112\n","loss: 0.090807  [   20]/  112\n","loss: 0.068879  [   30]/  112\n","loss: 0.154403  [   40]/  112\n","loss: 0.164554  [   50]/  112\n","loss: 0.674236  [   60]/  112\n","loss: 0.132159  [   70]/  112\n","loss: 0.102163  [   80]/  112\n","loss: 0.106866  [   90]/  112\n","loss: 0.116079  [  100]/  112\n","loss: 0.187496  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.163004\n","\n","Epoch 28 \n","------------------------\n","loss: 0.328089  [    0]/  112\n","loss: 0.269355  [   10]/  112\n","loss: 0.110805  [   20]/  112\n","loss: 0.065165  [   30]/  112\n","loss: 0.064593  [   40]/  112\n","loss: 0.365153  [   50]/  112\n","loss: 0.061250  [   60]/  112\n","loss: 0.125064  [   70]/  112\n","loss: 0.099197  [   80]/  112\n","loss: 0.227981  [   90]/  112\n","loss: 0.177915  [  100]/  112\n","loss: 0.185754  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.180764\n","\n","Epoch 29 \n","------------------------\n","loss: 0.221710  [    0]/  112\n","loss: 0.075273  [   10]/  112\n","loss: 0.114889  [   20]/  112\n","loss: 0.081461  [   30]/  112\n","loss: 0.104048  [   40]/  112\n","loss: 0.091627  [   50]/  112\n","loss: 0.539745  [   60]/  112\n","loss: 0.183402  [   70]/  112\n","loss: 0.046991  [   80]/  112\n","loss: 0.129183  [   90]/  112\n","loss: 0.263339  [  100]/  112\n","loss: 0.087975  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.153977\n","\n","Epoch 30 \n","------------------------\n","loss: 0.098612  [    0]/  112\n","loss: 0.240133  [   10]/  112\n","loss: 0.082501  [   20]/  112\n","loss: 0.144973  [   30]/  112\n","loss: 0.158463  [   40]/  112\n","loss: 0.335142  [   50]/  112\n","loss: 0.137106  [   60]/  112\n","loss: 0.109677  [   70]/  112\n","loss: 0.228370  [   80]/  112\n","loss: 0.110680  [   90]/  112\n","loss: 0.062766  [  100]/  112\n","loss: 0.026193  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.171219\n","\n","Epoch 31 \n","------------------------\n","loss: 0.078032  [    0]/  112\n","loss: 0.121285  [   10]/  112\n","loss: 0.264772  [   20]/  112\n","loss: 0.264434  [   30]/  112\n","loss: 0.057321  [   40]/  112\n","loss: 0.077885  [   50]/  112\n","loss: 0.055449  [   60]/  112\n","loss: 0.135348  [   70]/  112\n","loss: 0.084231  [   80]/  112\n","loss: 0.231310  [   90]/  112\n","loss: 0.255224  [  100]/  112\n","loss: 0.197657  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.148264\n","\n","Epoch 32 \n","------------------------\n","loss: 0.068280  [    0]/  112\n","loss: 0.068327  [   10]/  112\n","loss: 0.279321  [   20]/  112\n","loss: 0.116641  [   30]/  112\n","loss: 0.212302  [   40]/  112\n","loss: 0.270623  [   50]/  112\n","loss: 0.092668  [   60]/  112\n","loss: 0.135566  [   70]/  112\n","loss: 0.097663  [   80]/  112\n","loss: 0.058727  [   90]/  112\n","loss: 0.228410  [  100]/  112\n","loss: 0.152546  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.154037\n","\n","Epoch 33 \n","------------------------\n","loss: 0.149053  [    0]/  112\n","loss: 0.098394  [   10]/  112\n","loss: 0.209852  [   20]/  112\n","loss: 0.231685  [   30]/  112\n","loss: 0.044397  [   40]/  112\n","loss: 0.054311  [   50]/  112\n","loss: 0.210678  [   60]/  112\n","loss: 0.231229  [   70]/  112\n","loss: 0.187040  [   80]/  112\n","loss: 0.132199  [   90]/  112\n","loss: 0.051930  [  100]/  112\n","loss: 0.121079  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.153503\n","\n","Epoch 34 \n","------------------------\n","loss: 0.080076  [    0]/  112\n","loss: 0.086398  [   10]/  112\n","loss: 0.121102  [   20]/  112\n","loss: 0.101862  [   30]/  112\n","loss: 0.387844  [   40]/  112\n","loss: 0.217670  [   50]/  112\n","loss: 0.143525  [   60]/  112\n","loss: 0.077022  [   70]/  112\n","loss: 0.122426  [   80]/  112\n","loss: 0.073794  [   90]/  112\n","loss: 0.129731  [  100]/  112\n","loss: 0.072595  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.138953\n","\n","Epoch 35 \n","------------------------\n","loss: 0.211177  [    0]/  112\n","loss: 0.172031  [   10]/  112\n","loss: 0.042294  [   20]/  112\n","loss: 0.120907  [   30]/  112\n","loss: 0.133031  [   40]/  112\n","loss: 0.166954  [   50]/  112\n","loss: 0.134582  [   60]/  112\n","loss: 0.195192  [   70]/  112\n","loss: 0.035951  [   80]/  112\n","loss: 0.223887  [   90]/  112\n","loss: 0.054033  [  100]/  112\n","loss: 0.189853  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.137015\n","\n","Epoch 36 \n","------------------------\n","loss: 0.068240  [    0]/  112\n","loss: 0.271077  [   10]/  112\n","loss: 0.182414  [   20]/  112\n","loss: 0.108398  [   30]/  112\n","loss: 0.095886  [   40]/  112\n","loss: 0.083839  [   50]/  112\n","loss: 0.102942  [   60]/  112\n","loss: 0.398267  [   70]/  112\n","loss: 0.064344  [   80]/  112\n","loss: 0.076606  [   90]/  112\n","loss: 0.115390  [  100]/  112\n","loss: 0.010981  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.129186\n","\n","Epoch 37 \n","------------------------\n","loss: 0.223381  [    0]/  112\n","loss: 0.119412  [   10]/  112\n","loss: 0.196441  [   20]/  112\n","loss: 0.078761  [   30]/  112\n","loss: 0.118019  [   40]/  112\n","loss: 0.176315  [   50]/  112\n","loss: 0.041262  [   60]/  112\n","loss: 0.062654  [   70]/  112\n","loss: 0.181394  [   80]/  112\n","loss: 0.036244  [   90]/  112\n","loss: 0.250080  [  100]/  112\n","loss: 0.342943  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.133538\n","\n","Epoch 38 \n","------------------------\n","loss: 0.040079  [    0]/  112\n","loss: 0.031410  [   10]/  112\n","loss: 0.056620  [   20]/  112\n","loss: 0.102680  [   30]/  112\n","loss: 0.076160  [   40]/  112\n","loss: 0.154992  [   50]/  112\n","loss: 0.073633  [   60]/  112\n","loss: 0.278245  [   70]/  112\n","loss: 0.380535  [   80]/  112\n","loss: 0.070322  [   90]/  112\n","loss: 0.256455  [  100]/  112\n","loss: 0.070248  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.124236\n","\n","Epoch 39 \n","------------------------\n","loss: 0.058855  [    0]/  112\n","loss: 0.055785  [   10]/  112\n","loss: 0.095609  [   20]/  112\n","loss: 0.344605  [   30]/  112\n","loss: 0.070273  [   40]/  112\n","loss: 0.076904  [   50]/  112\n","loss: 0.103954  [   60]/  112\n","loss: 0.131312  [   70]/  112\n","loss: 0.213797  [   80]/  112\n","loss: 0.152781  [   90]/  112\n","loss: 0.132525  [  100]/  112\n","loss: 0.081057  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.134018\n","\n","Epoch 40 \n","------------------------\n","loss: 0.225094  [    0]/  112\n","loss: 0.187614  [   10]/  112\n","loss: 0.081544  [   20]/  112\n","loss: 0.016875  [   30]/  112\n","loss: 0.088719  [   40]/  112\n","loss: 0.073393  [   50]/  112\n","loss: 0.121240  [   60]/  112\n","loss: 0.117800  [   70]/  112\n","loss: 0.040690  [   80]/  112\n","loss: 0.370066  [   90]/  112\n","loss: 0.062725  [  100]/  112\n","loss: 0.155651  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.119964\n","\n","Epoch 41 \n","------------------------\n","loss: 0.089647  [    0]/  112\n","loss: 0.102944  [   10]/  112\n","loss: 0.032812  [   20]/  112\n","loss: 0.263360  [   30]/  112\n","loss: 0.351932  [   40]/  112\n","loss: 0.040959  [   50]/  112\n","loss: 0.108136  [   60]/  112\n","loss: 0.064872  [   70]/  112\n","loss: 0.069867  [   80]/  112\n","loss: 0.146963  [   90]/  112\n","loss: 0.081703  [  100]/  112\n","loss: 0.270756  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.123750\n","\n","Epoch 42 \n","------------------------\n","loss: 0.039567  [    0]/  112\n","loss: 0.086703  [   10]/  112\n","loss: 0.194803  [   20]/  112\n","loss: 0.196311  [   30]/  112\n","loss: 0.224226  [   40]/  112\n","loss: 0.243344  [   50]/  112\n","loss: 0.093221  [   60]/  112\n","loss: 0.074575  [   70]/  112\n","loss: 0.084013  [   80]/  112\n","loss: 0.101416  [   90]/  112\n","loss: 0.113273  [  100]/  112\n","loss: 0.054181  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.120192\n","\n","Epoch 43 \n","------------------------\n","loss: 0.074724  [    0]/  112\n","loss: 0.126156  [   10]/  112\n","loss: 0.167815  [   20]/  112\n","loss: 0.104788  [   30]/  112\n","loss: 0.234057  [   40]/  112\n","loss: 0.037492  [   50]/  112\n","loss: 0.163149  [   60]/  112\n","loss: 0.070067  [   70]/  112\n","loss: 0.037639  [   80]/  112\n","loss: 0.193670  [   90]/  112\n","loss: 0.086050  [  100]/  112\n","loss: 0.348805  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.126659\n","\n","Epoch 44 \n","------------------------\n","loss: 0.170301  [    0]/  112\n","loss: 0.193812  [   10]/  112\n","loss: 0.025393  [   20]/  112\n","loss: 0.207505  [   30]/  112\n","loss: 0.066855  [   40]/  112\n","loss: 0.154307  [   50]/  112\n","loss: 0.101005  [   60]/  112\n","loss: 0.079139  [   70]/  112\n","loss: 0.080533  [   80]/  112\n","loss: 0.042780  [   90]/  112\n","loss: 0.095592  [  100]/  112\n","loss: 0.187404  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.116006\n","\n","Epoch 45 \n","------------------------\n","loss: 0.084888  [    0]/  112\n","loss: 0.267383  [   10]/  112\n","loss: 0.105631  [   20]/  112\n","loss: 0.131729  [   30]/  112\n","loss: 0.055178  [   40]/  112\n","loss: 0.065562  [   50]/  112\n","loss: 0.023269  [   60]/  112\n","loss: 0.060531  [   70]/  112\n","loss: 0.237987  [   80]/  112\n","loss: 0.172277  [   90]/  112\n","loss: 0.092677  [  100]/  112\n","loss: 0.297137  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.114926\n","\n","Epoch 46 \n","------------------------\n","loss: 0.279928  [    0]/  112\n","loss: 0.092990  [   10]/  112\n","loss: 0.066258  [   20]/  112\n","loss: 0.030531  [   30]/  112\n","loss: 0.223258  [   40]/  112\n","loss: 0.021553  [   50]/  112\n","loss: 0.219191  [   60]/  112\n","loss: 0.061990  [   70]/  112\n","loss: 0.091175  [   80]/  112\n","loss: 0.121661  [   90]/  112\n","loss: 0.071726  [  100]/  112\n","loss: 0.012514  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.112673\n","\n","Epoch 47 \n","------------------------\n","loss: 0.069700  [    0]/  112\n","loss: 0.122864  [   10]/  112\n","loss: 0.273295  [   20]/  112\n","loss: 0.052557  [   30]/  112\n","loss: 0.106975  [   40]/  112\n","loss: 0.185595  [   50]/  112\n","loss: 0.076945  [   60]/  112\n","loss: 0.131097  [   70]/  112\n","loss: 0.131518  [   80]/  112\n","loss: 0.071482  [   90]/  112\n","loss: 0.050601  [  100]/  112\n","loss: 0.020391  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.110061\n","\n","Epoch 48 \n","------------------------\n","loss: 0.040549  [    0]/  112\n","loss: 0.229088  [   10]/  112\n","loss: 0.089073  [   20]/  112\n","loss: 0.167787  [   30]/  112\n","loss: 0.068838  [   40]/  112\n","loss: 0.048446  [   50]/  112\n","loss: 0.226211  [   60]/  112\n","loss: 0.067020  [   70]/  112\n","loss: 0.048052  [   80]/  112\n","loss: 0.083871  [   90]/  112\n","loss: 0.132509  [  100]/  112\n","loss: 0.163689  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.106513\n","\n","Epoch 49 \n","------------------------\n","loss: 0.093137  [    0]/  112\n","loss: 0.070706  [   10]/  112\n","loss: 0.221980  [   20]/  112\n","loss: 0.186720  [   30]/  112\n","loss: 0.062747  [   40]/  112\n","loss: 0.018403  [   50]/  112\n","loss: 0.198588  [   60]/  112\n","loss: 0.240886  [   70]/  112\n","loss: 0.024356  [   80]/  112\n","loss: 0.117849  [   90]/  112\n","loss: 0.071757  [  100]/  112\n","loss: 0.049333  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.111605\n","\n","Epoch 50 \n","------------------------\n","loss: 0.115021  [    0]/  112\n","loss: 0.038853  [   10]/  112\n","loss: 0.048215  [   20]/  112\n","loss: 0.049253  [   30]/  112\n","loss: 0.259026  [   40]/  112\n","loss: 0.035307  [   50]/  112\n","loss: 0.204262  [   60]/  112\n","loss: 0.073410  [   70]/  112\n","loss: 0.089719  [   80]/  112\n","loss: 0.163722  [   90]/  112\n","loss: 0.087997  [  100]/  112\n","loss: 0.047815  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.108175\n","\n","Epoch 51 \n","------------------------\n","loss: 0.050056  [    0]/  112\n","loss: 0.115499  [   10]/  112\n","loss: 0.034692  [   20]/  112\n","loss: 0.095028  [   30]/  112\n","loss: 0.097130  [   40]/  112\n","loss: 0.146090  [   50]/  112\n","loss: 0.043519  [   60]/  112\n","loss: 0.375706  [   70]/  112\n","loss: 0.188785  [   80]/  112\n","loss: 0.051493  [   90]/  112\n","loss: 0.037549  [  100]/  112\n","loss: 0.034476  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.105477\n","\n","Epoch 52 \n","------------------------\n","loss: 0.181809  [    0]/  112\n","loss: 0.099040  [   10]/  112\n","loss: 0.062753  [   20]/  112\n","loss: 0.073103  [   30]/  112\n","loss: 0.055294  [   40]/  112\n","loss: 0.204209  [   50]/  112\n","loss: 0.012730  [   60]/  112\n","loss: 0.137849  [   70]/  112\n","loss: 0.259175  [   80]/  112\n","loss: 0.076313  [   90]/  112\n","loss: 0.120334  [  100]/  112\n","loss: 0.009246  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.117992\n","\n","Epoch 53 \n","------------------------\n","loss: 0.090526  [    0]/  112\n","loss: 0.086668  [   10]/  112\n","loss: 0.351967  [   20]/  112\n","loss: 0.109462  [   30]/  112\n","loss: 0.036558  [   40]/  112\n","loss: 0.034561  [   50]/  112\n","loss: 0.096623  [   60]/  112\n","loss: 0.175784  [   70]/  112\n","loss: 0.073723  [   80]/  112\n","loss: 0.040045  [   90]/  112\n","loss: 0.099351  [  100]/  112\n","loss: 0.172828  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.096556\n","\n","Epoch 54 \n","------------------------\n","loss: 0.246390  [    0]/  112\n","loss: 0.098047  [   10]/  112\n","loss: 0.201148  [   20]/  112\n","loss: 0.078259  [   30]/  112\n","loss: 0.193689  [   40]/  112\n","loss: 0.107537  [   50]/  112\n","loss: 0.048891  [   60]/  112\n","loss: 0.057389  [   70]/  112\n","loss: 0.066244  [   80]/  112\n","loss: 0.038824  [   90]/  112\n","loss: 0.055482  [  100]/  112\n","loss: 0.025196  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.125152\n","\n","Epoch 55 \n","------------------------\n","loss: 0.043172  [    0]/  112\n","loss: 0.084318  [   10]/  112\n","loss: 0.013245  [   20]/  112\n","loss: 0.190161  [   30]/  112\n","loss: 0.021423  [   40]/  112\n","loss: 0.055034  [   50]/  112\n","loss: 0.146329  [   60]/  112\n","loss: 0.019127  [   70]/  112\n","loss: 0.272964  [   80]/  112\n","loss: 0.176907  [   90]/  112\n","loss: 0.082953  [  100]/  112\n","loss: 0.075652  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.100368\n","\n","Epoch 56 \n","------------------------\n","loss: 0.069049  [    0]/  112\n","loss: 0.242402  [   10]/  112\n","loss: 0.067860  [   20]/  112\n","loss: 0.043195  [   30]/  112\n","loss: 0.058130  [   40]/  112\n","loss: 0.027960  [   50]/  112\n","loss: 0.068470  [   60]/  112\n","loss: 0.067704  [   70]/  112\n","loss: 0.060155  [   80]/  112\n","loss: 0.095632  [   90]/  112\n","loss: 0.290245  [  100]/  112\n","loss: 0.083390  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.096678\n","\n","Epoch 57 \n","------------------------\n","loss: 0.094273  [    0]/  112\n","loss: 0.056507  [   10]/  112\n","loss: 0.059039  [   20]/  112\n","loss: 0.083319  [   30]/  112\n","loss: 0.277024  [   40]/  112\n","loss: 0.182509  [   50]/  112\n","loss: 0.056499  [   60]/  112\n","loss: 0.179322  [   70]/  112\n","loss: 0.060921  [   80]/  112\n","loss: 0.054359  [   90]/  112\n","loss: 0.024046  [  100]/  112\n","loss: 0.003497  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.104429\n","\n","Epoch 58 \n","------------------------\n","loss: 0.022577  [    0]/  112\n","loss: 0.147377  [   10]/  112\n","loss: 0.058049  [   20]/  112\n","loss: 0.235124  [   30]/  112\n","loss: 0.190617  [   40]/  112\n","loss: 0.061811  [   50]/  112\n","loss: 0.227951  [   60]/  112\n","loss: 0.033891  [   70]/  112\n","loss: 0.028201  [   80]/  112\n","loss: 0.045649  [   90]/  112\n","loss: 0.074515  [  100]/  112\n","loss: 0.001264  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.096350\n","\n","Epoch 59 \n","------------------------\n","loss: 0.037649  [    0]/  112\n","loss: 0.064642  [   10]/  112\n","loss: 0.038394  [   20]/  112\n","loss: 0.084714  [   30]/  112\n","loss: 0.049843  [   40]/  112\n","loss: 0.252536  [   50]/  112\n","loss: 0.042907  [   60]/  112\n","loss: 0.086415  [   70]/  112\n","loss: 0.008506  [   80]/  112\n","loss: 0.278046  [   90]/  112\n","loss: 0.229155  [  100]/  112\n","loss: 0.035046  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.089345\n","\n","Epoch 60 \n","------------------------\n","loss: 0.035784  [    0]/  112\n","loss: 0.126534  [   10]/  112\n","loss: 0.129317  [   20]/  112\n","loss: 0.184913  [   30]/  112\n","loss: 0.201787  [   40]/  112\n","loss: 0.112448  [   50]/  112\n","loss: 0.041546  [   60]/  112\n","loss: 0.221791  [   70]/  112\n","loss: 0.036164  [   80]/  112\n","loss: 0.065964  [   90]/  112\n","loss: 0.071291  [  100]/  112\n","loss: 0.004154  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.102793\n","\n","Epoch 61 \n","------------------------\n","loss: 0.101152  [    0]/  112\n","loss: 0.033635  [   10]/  112\n","loss: 0.215134  [   20]/  112\n","loss: 0.027497  [   30]/  112\n","loss: 0.085177  [   40]/  112\n","loss: 0.343754  [   50]/  112\n","loss: 0.050195  [   60]/  112\n","loss: 0.106726  [   70]/  112\n","loss: 0.022120  [   80]/  112\n","loss: 0.034864  [   90]/  112\n","loss: 0.067023  [  100]/  112\n","loss: 0.009461  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.094276\n","\n","Epoch 62 \n","------------------------\n","loss: 0.055818  [    0]/  112\n","loss: 0.064306  [   10]/  112\n","loss: 0.221595  [   20]/  112\n","loss: 0.019030  [   30]/  112\n","loss: 0.231955  [   40]/  112\n","loss: 0.019766  [   50]/  112\n","loss: 0.071717  [   60]/  112\n","loss: 0.074531  [   70]/  112\n","loss: 0.128676  [   80]/  112\n","loss: 0.028962  [   90]/  112\n","loss: 0.124435  [  100]/  112\n","loss: 0.001125  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.097761\n","\n","Epoch 63 \n","------------------------\n","loss: 0.231492  [    0]/  112\n","loss: 0.021946  [   10]/  112\n","loss: 0.060565  [   20]/  112\n","loss: 0.135977  [   30]/  112\n","loss: 0.048209  [   40]/  112\n","loss: 0.016686  [   50]/  112\n","loss: 0.086542  [   60]/  112\n","loss: 0.234416  [   70]/  112\n","loss: 0.049009  [   80]/  112\n","loss: 0.048454  [   90]/  112\n","loss: 0.101057  [  100]/  112\n","loss: 0.076260  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.090266\n","\n","Epoch 64 \n","------------------------\n","loss: 0.042455  [    0]/  112\n","loss: 0.070908  [   10]/  112\n","loss: 0.026444  [   20]/  112\n","loss: 0.037332  [   30]/  112\n","loss: 0.092419  [   40]/  112\n","loss: 0.003656  [   50]/  112\n","loss: 0.047548  [   60]/  112\n","loss: 0.054514  [   70]/  112\n","loss: 0.109091  [   80]/  112\n","loss: 0.248386  [   90]/  112\n","loss: 0.169177  [  100]/  112\n","loss: 0.639968  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.098362\n","\n","Epoch 65 \n","------------------------\n","loss: 0.054888  [    0]/  112\n","loss: 0.029518  [   10]/  112\n","loss: 0.022959  [   20]/  112\n","loss: 0.138233  [   30]/  112\n","loss: 0.085598  [   40]/  112\n","loss: 0.186708  [   50]/  112\n","loss: 0.076778  [   60]/  112\n","loss: 0.011412  [   70]/  112\n","loss: 0.160453  [   80]/  112\n","loss: 0.355991  [   90]/  112\n","loss: 0.120321  [  100]/  112\n","loss: 0.004541  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.100418\n","\n","Epoch 66 \n","------------------------\n","loss: 0.014755  [    0]/  112\n","loss: 0.089193  [   10]/  112\n","loss: 0.022438  [   20]/  112\n","loss: 0.055897  [   30]/  112\n","loss: 0.041667  [   40]/  112\n","loss: 0.055858  [   50]/  112\n","loss: 0.059754  [   60]/  112\n","loss: 0.168810  [   70]/  112\n","loss: 0.086307  [   80]/  112\n","loss: 0.284258  [   90]/  112\n","loss: 0.200030  [  100]/  112\n","loss: 0.007025  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.090351\n","\n","Epoch 67 \n","------------------------\n","loss: 0.198092  [    0]/  112\n","loss: 0.037048  [   10]/  112\n","loss: 0.018939  [   20]/  112\n","loss: 0.049409  [   30]/  112\n","loss: 0.022094  [   40]/  112\n","loss: 0.092524  [   50]/  112\n","loss: 0.187998  [   60]/  112\n","loss: 0.294638  [   70]/  112\n","loss: 0.021026  [   80]/  112\n","loss: 0.009417  [   90]/  112\n","loss: 0.109912  [  100]/  112\n","loss: 0.004293  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.106192\n","\n","Epoch 68 \n","------------------------\n","loss: 0.065142  [    0]/  112\n","loss: 0.070521  [   10]/  112\n","loss: 0.167129  [   20]/  112\n","loss: 0.094098  [   30]/  112\n","loss: 0.119082  [   40]/  112\n","loss: 0.147317  [   50]/  112\n","loss: 0.051274  [   60]/  112\n","loss: 0.154879  [   70]/  112\n","loss: 0.058615  [   80]/  112\n","loss: 0.035521  [   90]/  112\n","loss: 0.012353  [  100]/  112\n","loss: 0.042071  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.082546\n","\n","Epoch 69 \n","------------------------\n","loss: 0.043956  [    0]/  112\n","loss: 0.160611  [   10]/  112\n","loss: 0.307636  [   20]/  112\n","loss: 0.093348  [   30]/  112\n","loss: 0.185187  [   40]/  112\n","loss: 0.027409  [   50]/  112\n","loss: 0.025686  [   60]/  112\n","loss: 0.055130  [   70]/  112\n","loss: 0.034881  [   80]/  112\n","loss: 0.025578  [   90]/  112\n","loss: 0.009782  [  100]/  112\n","loss: 0.038463  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.082911\n","\n","Epoch 70 \n","------------------------\n","loss: 0.064184  [    0]/  112\n","loss: 0.187415  [   10]/  112\n","loss: 0.050388  [   20]/  112\n","loss: 0.047408  [   30]/  112\n","loss: 0.036070  [   40]/  112\n","loss: 0.009395  [   50]/  112\n","loss: 0.022875  [   60]/  112\n","loss: 0.038922  [   70]/  112\n","loss: 0.082347  [   80]/  112\n","loss: 0.202659  [   90]/  112\n","loss: 0.186848  [  100]/  112\n","loss: 0.153732  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.082424\n","\n","Epoch 71 \n","------------------------\n","loss: 0.119435  [    0]/  112\n","loss: 0.129085  [   10]/  112\n","loss: 0.019112  [   20]/  112\n","loss: 0.026864  [   30]/  112\n","loss: 0.221454  [   40]/  112\n","loss: 0.171133  [   50]/  112\n","loss: 0.146652  [   60]/  112\n","loss: 0.016678  [   70]/  112\n","loss: 0.014485  [   80]/  112\n","loss: 0.019115  [   90]/  112\n","loss: 0.071944  [  100]/  112\n","loss: 0.005120  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.080761\n","\n","Epoch 72 \n","------------------------\n","loss: 0.022955  [    0]/  112\n","loss: 0.039815  [   10]/  112\n","loss: 0.175565  [   20]/  112\n","loss: 0.168648  [   30]/  112\n","loss: 0.085173  [   40]/  112\n","loss: 0.031750  [   50]/  112\n","loss: 0.044222  [   60]/  112\n","loss: 0.065077  [   70]/  112\n","loss: 0.179587  [   80]/  112\n","loss: 0.037960  [   90]/  112\n","loss: 0.124019  [  100]/  112\n","loss: 0.079102  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.087107\n","\n","Epoch 73 \n","------------------------\n","loss: 0.056166  [    0]/  112\n","loss: 0.149311  [   10]/  112\n","loss: 0.008531  [   20]/  112\n","loss: 0.109760  [   30]/  112\n","loss: 0.095853  [   40]/  112\n","loss: 0.226332  [   50]/  112\n","loss: 0.053178  [   60]/  112\n","loss: 0.022321  [   70]/  112\n","loss: 0.045185  [   80]/  112\n","loss: 0.030315  [   90]/  112\n","loss: 0.150306  [  100]/  112\n","loss: 0.009905  [   22]/  112\n","Test Error: \n"," Accuracy: 100.0%, Avg loss: 0.076071\n","\n","Epoch 74 \n","------------------------\n","loss: 0.069035  [    0]/  112\n","loss: 0.028071  [   10]/  112\n","loss: 0.017669  [   20]/  112\n","loss: 0.041783  [   30]/  112\n","loss: 0.143467  [   40]/  112\n","loss: 0.096886  [   50]/  112\n","loss: 0.044402  [   60]/  112\n","loss: 0.096289  [   70]/  112\n","loss: 0.025185  [   80]/  112\n","loss: 0.165336  [   90]/  112\n","loss: 0.015270  [  100]/  112\n","loss: 0.945038  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.098138\n","\n","Epoch 75 \n","------------------------\n","loss: 0.119918  [    0]/  112\n","loss: 0.160851  [   10]/  112\n","loss: 0.012080  [   20]/  112\n","loss: 0.338668  [   30]/  112\n","loss: 0.150360  [   40]/  112\n","loss: 0.070958  [   50]/  112\n","loss: 0.162446  [   60]/  112\n","loss: 0.106100  [   70]/  112\n","loss: 0.134323  [   80]/  112\n","loss: 0.171955  [   90]/  112\n","loss: 0.043096  [  100]/  112\n","loss: 0.004920  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.100663\n","\n","Epoch 76 \n","------------------------\n","loss: 0.124382  [    0]/  112\n","loss: 0.024806  [   10]/  112\n","loss: 0.250005  [   20]/  112\n","loss: 0.152821  [   30]/  112\n","loss: 0.052222  [   40]/  112\n","loss: 0.015117  [   50]/  112\n","loss: 0.156678  [   60]/  112\n","loss: 0.012642  [   70]/  112\n","loss: 0.034027  [   80]/  112\n","loss: 0.070025  [   90]/  112\n","loss: 0.070625  [  100]/  112\n","loss: 0.008964  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.078403\n","\n","Epoch 77 \n","------------------------\n","loss: 0.024181  [    0]/  112\n","loss: 0.148315  [   10]/  112\n","loss: 0.024163  [   20]/  112\n","loss: 0.032909  [   30]/  112\n","loss: 0.107174  [   40]/  112\n","loss: 0.040629  [   50]/  112\n","loss: 0.014532  [   60]/  112\n","loss: 0.043362  [   70]/  112\n","loss: 0.058150  [   80]/  112\n","loss: 0.056548  [   90]/  112\n","loss: 0.351676  [  100]/  112\n","loss: 0.256876  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.077690\n","\n","Epoch 78 \n","------------------------\n","loss: 0.045848  [    0]/  112\n","loss: 0.082239  [   10]/  112\n","loss: 0.158414  [   20]/  112\n","loss: 0.043365  [   30]/  112\n","loss: 0.032522  [   40]/  112\n","loss: 0.351769  [   50]/  112\n","loss: 0.104497  [   60]/  112\n","loss: 0.016675  [   70]/  112\n","loss: 0.035825  [   80]/  112\n","loss: 0.014396  [   90]/  112\n","loss: 0.058494  [  100]/  112\n","loss: 0.011175  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.095633\n","\n","Epoch 79 \n","------------------------\n","loss: 0.032529  [    0]/  112\n","loss: 0.083841  [   10]/  112\n","loss: 0.275650  [   20]/  112\n","loss: 0.021312  [   30]/  112\n","loss: 0.073379  [   40]/  112\n","loss: 0.085758  [   50]/  112\n","loss: 0.148756  [   60]/  112\n","loss: 0.032872  [   70]/  112\n","loss: 0.022013  [   80]/  112\n","loss: 0.115415  [   90]/  112\n","loss: 0.013822  [  100]/  112\n","loss: 0.038786  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.081569\n","\n","Epoch 80 \n","------------------------\n","loss: 0.088111  [    0]/  112\n","loss: 0.119924  [   10]/  112\n","loss: 0.020737  [   20]/  112\n","loss: 0.014165  [   30]/  112\n","loss: 0.031506  [   40]/  112\n","loss: 0.057262  [   50]/  112\n","loss: 0.205244  [   60]/  112\n","loss: 0.252066  [   70]/  112\n","loss: 0.095065  [   80]/  112\n","loss: 0.016446  [   90]/  112\n","loss: 0.017132  [  100]/  112\n","loss: 0.005952  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.075655\n","\n","Epoch 81 \n","------------------------\n","loss: 0.068800  [    0]/  112\n","loss: 0.039893  [   10]/  112\n","loss: 0.028066  [   20]/  112\n","loss: 0.016000  [   30]/  112\n","loss: 0.157952  [   40]/  112\n","loss: 0.131992  [   50]/  112\n","loss: 0.009412  [   60]/  112\n","loss: 0.201080  [   70]/  112\n","loss: 0.007549  [   80]/  112\n","loss: 0.043674  [   90]/  112\n","loss: 0.180669  [  100]/  112\n","loss: 0.331819  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.088023\n","\n","Epoch 82 \n","------------------------\n","loss: 0.034176  [    0]/  112\n","loss: 0.081755  [   10]/  112\n","loss: 0.020715  [   20]/  112\n","loss: 0.393988  [   30]/  112\n","loss: 0.142351  [   40]/  112\n","loss: 0.022072  [   50]/  112\n","loss: 0.140336  [   60]/  112\n","loss: 0.031862  [   70]/  112\n","loss: 0.015646  [   80]/  112\n","loss: 0.053921  [   90]/  112\n","loss: 0.034673  [  100]/  112\n","loss: 0.003990  [   22]/  112\n","Test Error: \n"," Accuracy: 100.0%, Avg loss: 0.072222\n","\n","Epoch 83 \n","------------------------\n","loss: 0.022404  [    0]/  112\n","loss: 0.016445  [   10]/  112\n","loss: 0.143146  [   20]/  112\n","loss: 0.022556  [   30]/  112\n","loss: 0.060731  [   40]/  112\n","loss: 0.045845  [   50]/  112\n","loss: 0.248418  [   60]/  112\n","loss: 0.219446  [   70]/  112\n","loss: 0.085672  [   80]/  112\n","loss: 0.022525  [   90]/  112\n","loss: 0.014713  [  100]/  112\n","loss: 0.002865  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.084450\n","\n","Epoch 84 \n","------------------------\n","loss: 0.033626  [    0]/  112\n","loss: 0.109849  [   10]/  112\n","loss: 0.094167  [   20]/  112\n","loss: 0.065784  [   30]/  112\n","loss: 0.065986  [   40]/  112\n","loss: 0.131364  [   50]/  112\n","loss: 0.014231  [   60]/  112\n","loss: 0.069490  [   70]/  112\n","loss: 0.282410  [   80]/  112\n","loss: 0.028393  [   90]/  112\n","loss: 0.004313  [  100]/  112\n","loss: 0.149995  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.075693\n","\n","Epoch 85 \n","------------------------\n","loss: 0.197574  [    0]/  112\n","loss: 0.021815  [   10]/  112\n","loss: 0.025339  [   20]/  112\n","loss: 0.140821  [   30]/  112\n","loss: 0.030709  [   40]/  112\n","loss: 0.058481  [   50]/  112\n","loss: 0.050682  [   60]/  112\n","loss: 0.044935  [   70]/  112\n","loss: 0.036970  [   80]/  112\n","loss: 0.172436  [   90]/  112\n","loss: 0.063680  [  100]/  112\n","loss: 0.191792  [   22]/  112\n","Test Error: \n"," Accuracy: 100.0%, Avg loss: 0.068215\n","\n","Epoch 86 \n","------------------------\n","loss: 0.078010  [    0]/  112\n","loss: 0.069959  [   10]/  112\n","loss: 0.030552  [   20]/  112\n","loss: 0.037489  [   30]/  112\n","loss: 0.131662  [   40]/  112\n","loss: 0.019578  [   50]/  112\n","loss: 0.049100  [   60]/  112\n","loss: 0.062790  [   70]/  112\n","loss: 0.175973  [   80]/  112\n","loss: 0.117884  [   90]/  112\n","loss: 0.016941  [  100]/  112\n","loss: 0.176859  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.087799\n","\n","Epoch 87 \n","------------------------\n","loss: 0.010867  [    0]/  112\n","loss: 0.022075  [   10]/  112\n","loss: 0.023979  [   20]/  112\n","loss: 0.033984  [   30]/  112\n","loss: 0.046111  [   40]/  112\n","loss: 0.229902  [   50]/  112\n","loss: 0.033254  [   60]/  112\n","loss: 0.123638  [   70]/  112\n","loss: 0.038602  [   80]/  112\n","loss: 0.111784  [   90]/  112\n","loss: 0.189951  [  100]/  112\n","loss: 0.077098  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.073539\n","\n","Epoch 88 \n","------------------------\n","loss: 0.192209  [    0]/  112\n","loss: 0.155974  [   10]/  112\n","loss: 0.117796  [   20]/  112\n","loss: 0.052446  [   30]/  112\n","loss: 0.064044  [   40]/  112\n","loss: 0.078039  [   50]/  112\n","loss: 0.012981  [   60]/  112\n","loss: 0.076866  [   70]/  112\n","loss: 0.047555  [   80]/  112\n","loss: 0.018900  [   90]/  112\n","loss: 0.036892  [  100]/  112\n","loss: 0.000655  [   22]/  112\n","Test Error: \n"," Accuracy: 100.0%, Avg loss: 0.072428\n","\n","Epoch 89 \n","------------------------\n","loss: 0.027024  [    0]/  112\n","loss: 0.043761  [   10]/  112\n","loss: 0.018771  [   20]/  112\n","loss: 0.237348  [   30]/  112\n","loss: 0.247938  [   40]/  112\n","loss: 0.025629  [   50]/  112\n","loss: 0.124743  [   60]/  112\n","loss: 0.036576  [   70]/  112\n","loss: 0.015172  [   80]/  112\n","loss: 0.077318  [   90]/  112\n","loss: 0.090973  [  100]/  112\n","loss: 0.006168  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.079232\n","\n","Epoch 90 \n","------------------------\n","loss: 0.090903  [    0]/  112\n","loss: 0.140938  [   10]/  112\n","loss: 0.027072  [   20]/  112\n","loss: 0.014539  [   30]/  112\n","loss: 0.040422  [   40]/  112\n","loss: 0.020959  [   50]/  112\n","loss: 0.072147  [   60]/  112\n","loss: 0.019601  [   70]/  112\n","loss: 0.212308  [   80]/  112\n","loss: 0.010565  [   90]/  112\n","loss: 0.209904  [  100]/  112\n","loss: 0.020785  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.069060\n","\n","Epoch 91 \n","------------------------\n","loss: 0.025796  [    0]/  112\n","loss: 0.011284  [   10]/  112\n","loss: 0.012460  [   20]/  112\n","loss: 0.185821  [   30]/  112\n","loss: 0.067609  [   40]/  112\n","loss: 0.170283  [   50]/  112\n","loss: 0.226196  [   60]/  112\n","loss: 0.053837  [   70]/  112\n","loss: 0.025264  [   80]/  112\n","loss: 0.032465  [   90]/  112\n","loss: 0.023612  [  100]/  112\n","loss: 0.002914  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.072985\n","\n","Epoch 92 \n","------------------------\n","loss: 0.031125  [    0]/  112\n","loss: 0.042239  [   10]/  112\n","loss: 0.241825  [   20]/  112\n","loss: 0.062140  [   30]/  112\n","loss: 0.149260  [   40]/  112\n","loss: 0.008790  [   50]/  112\n","loss: 0.006110  [   60]/  112\n","loss: 0.208876  [   70]/  112\n","loss: 0.031300  [   80]/  112\n","loss: 0.022963  [   90]/  112\n","loss: 0.036120  [  100]/  112\n","loss: 0.033486  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.076931\n","\n","Epoch 93 \n","------------------------\n","loss: 0.018871  [    0]/  112\n","loss: 0.040485  [   10]/  112\n","loss: 0.041645  [   20]/  112\n","loss: 0.097540  [   30]/  112\n","loss: 0.068930  [   40]/  112\n","loss: 0.130949  [   50]/  112\n","loss: 0.044271  [   60]/  112\n","loss: 0.009670  [   70]/  112\n","loss: 0.217501  [   80]/  112\n","loss: 0.052716  [   90]/  112\n","loss: 0.041434  [  100]/  112\n","loss: 0.539035  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.073917\n","\n","Epoch 94 \n","------------------------\n","loss: 0.041508  [    0]/  112\n","loss: 0.013413  [   10]/  112\n","loss: 0.032918  [   20]/  112\n","loss: 0.067178  [   30]/  112\n","loss: 0.105620  [   40]/  112\n","loss: 0.160275  [   50]/  112\n","loss: 0.015239  [   60]/  112\n","loss: 0.071985  [   70]/  112\n","loss: 0.015574  [   80]/  112\n","loss: 0.202359  [   90]/  112\n","loss: 0.186643  [  100]/  112\n","loss: 0.002249  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.091452\n","\n","Epoch 95 \n","------------------------\n","loss: 0.016098  [    0]/  112\n","loss: 0.159577  [   10]/  112\n","loss: 0.044095  [   20]/  112\n","loss: 0.042697  [   30]/  112\n","loss: 0.073858  [   40]/  112\n","loss: 0.057208  [   50]/  112\n","loss: 0.027658  [   60]/  112\n","loss: 0.020161  [   70]/  112\n","loss: 0.125586  [   80]/  112\n","loss: 0.279165  [   90]/  112\n","loss: 0.027819  [  100]/  112\n","loss: 0.003382  [   22]/  112\n","Test Error: \n"," Accuracy: 100.0%, Avg loss: 0.066746\n","\n","Epoch 96 \n","------------------------\n","loss: 0.042200  [    0]/  112\n","loss: 0.008879  [   10]/  112\n","loss: 0.136070  [   20]/  112\n","loss: 0.243178  [   30]/  112\n","loss: 0.182945  [   40]/  112\n","loss: 0.051717  [   50]/  112\n","loss: 0.017316  [   60]/  112\n","loss: 0.073176  [   70]/  112\n","loss: 0.029991  [   80]/  112\n","loss: 0.002605  [   90]/  112\n","loss: 0.040956  [  100]/  112\n","loss: 0.141947  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.074186\n","\n","Epoch 97 \n","------------------------\n","loss: 0.009129  [    0]/  112\n","loss: 0.016014  [   10]/  112\n","loss: 0.063808  [   20]/  112\n","loss: 0.029675  [   30]/  112\n","loss: 0.217164  [   40]/  112\n","loss: 0.272157  [   50]/  112\n","loss: 0.016169  [   60]/  112\n","loss: 0.022300  [   70]/  112\n","loss: 0.048438  [   80]/  112\n","loss: 0.004543  [   90]/  112\n","loss: 0.027664  [  100]/  112\n","loss: 0.605628  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.069345\n","\n","Epoch 98 \n","------------------------\n","loss: 0.029190  [    0]/  112\n","loss: 0.119729  [   10]/  112\n","loss: 0.085195  [   20]/  112\n","loss: 0.021790  [   30]/  112\n","loss: 0.109188  [   40]/  112\n","loss: 0.037593  [   50]/  112\n","loss: 0.022011  [   60]/  112\n","loss: 0.059799  [   70]/  112\n","loss: 0.264570  [   80]/  112\n","loss: 0.121815  [   90]/  112\n","loss: 0.010865  [  100]/  112\n","loss: 0.003057  [   22]/  112\n","Test Error: \n"," Accuracy: 94.7%, Avg loss: 0.098594\n","\n","Epoch 99 \n","------------------------\n","loss: 0.087277  [    0]/  112\n","loss: 0.145928  [   10]/  112\n","loss: 0.081621  [   20]/  112\n","loss: 0.037596  [   30]/  112\n","loss: 0.005081  [   40]/  112\n","loss: 0.059633  [   50]/  112\n","loss: 0.149402  [   60]/  112\n","loss: 0.022455  [   70]/  112\n","loss: 0.016098  [   80]/  112\n","loss: 0.116598  [   90]/  112\n","loss: 0.085310  [  100]/  112\n","loss: 0.093897  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.072895\n","\n","Epoch 100 \n","------------------------\n","loss: 0.007597  [    0]/  112\n","loss: 0.080953  [   10]/  112\n","loss: 0.041393  [   20]/  112\n","loss: 0.037394  [   30]/  112\n","loss: 0.034986  [   40]/  112\n","loss: 0.126308  [   50]/  112\n","loss: 0.023494  [   60]/  112\n","loss: 0.122175  [   70]/  112\n","loss: 0.030021  [   80]/  112\n","loss: 0.069267  [   90]/  112\n","loss: 0.231310  [  100]/  112\n","loss: 0.003764  [   22]/  112\n","Test Error: \n"," Accuracy: 97.4%, Avg loss: 0.072106\n","\n","Done!\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"provenance":[],"toc_visible":true},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}